vehicle:
  sensors:
    sensor_models:
# --------------------CAMERA 1------------------------------------------------
    - camera_model:
        library:
          vendor: applied
          model: generic
        name: CAMERA_4MB_IMAGE_NARROW_FRONT_WS_rgb
        mount:
          px: 1.5
          py: 0
          pz: 2.0
          rpy:
            roll: 0.0
            pitch: 0.0
            yaw: 0.0
        standard_params:
          frame_rate: 4.0
          field_of_view: {az: !math "pi / 180 * 28"}
          lens_params:
            center_position: {x: 0.0, y: 0.0}
            # radial_distortion: [-0.538934000000000, 0.322437000000000, 0.0, 0.0, 0.0, 0.0]
            # tangential_distortion: [-0.000159000000000000, -0.000146000000000000]
          sensor_params:
            resolution: {x: 2688, y: 1520}
            type: VISIBLE
        format:
          data: ROS_TOPIC
    - camera_model:
        library:
          vendor: applied
          model: generic
        name: CAMERA_4MB_IMAGE_NARROW_FRONT_WS_semantic
        mount:
          px: 1.5
          py: 0
          pz: 2.0
          rpy:
            roll: 0.0
            pitch: 0.0
            yaw: 0.0
        standard_params:
          frame_rate: 4.0
          field_of_view: {az: !math "pi / 180 * 28"}
          lens_params:
            center_position: {x: 0.0, y: 0.0}
            # radial_distortion: [-0.538934000000000, 0.322437000000000, 0.0, 0.0, 0.0, 0.0]
            # tangential_distortion: [-0.000159000000000000, -0.000146000000000000]
          sensor_params:
            resolution: {x: 2688, y: 1520}
            type: SEMANTIC_SEGMENTATION
        format:
          data: ROS_TOPIC
# --------------------CAMERA 2------------------------------------------------
    - camera_model:
        library:
          vendor: applied
          model: generic
        name: CAMERA_4MB_IMAGE_EXTWIDE_FRONT_WS_rgb
        mount:
          px: 1.5
          py: 0
          pz: 2.0
          rpy:
            roll: 0.0
            pitch: 0.0
            yaw: 0.0
        standard_params:
          frame_rate: 4.0
          field_of_view: {az: !math "pi / 180 * 100"}
          lens_params:
            center_position: {x: 0.0, y: 0.0}
            # radial_distortion: [-0.538934000000000, 0.322437000000000, 0.0, 0.0, 0.0, 0.0]
            # tangential_distortion: [-0.000159000000000000, -0.000146000000000000]
          sensor_params:
            resolution: {x: 2688, y: 1520}
            type: VISIBLE
        format:
          data: ROS_TOPIC
    - camera_model:
        library:
          vendor: applied
          model: generic
        name: CAMERA_4MB_IMAGE_EXTWIDE_FRONT_WS_semantic
        mount:
          px: 1.5
          py: 0
          pz: 2.0
          rpy:
            roll: 0.0
            pitch: 0.0
            yaw: 0.0
        standard_params:
          frame_rate: 4.0
          field_of_view: {az: !math "pi / 180 * 100"}
          lens_params:
            center_position: {x: 0.0, y: 0.0}
            # radial_distortion: [-0.538934000000000, 0.322437000000000, 0.0, 0.0, 0.0, 0.0]
            # tangential_distortion: [-0.000159000000000000, -0.000146000000000000]
          sensor_params:
            resolution: {x: 2688, y: 1520}
            type: SEMANTIC_SEGMENTATION
        format:
          data: ROS_TOPIC
  
# --------------------LIDAR 1------------------------------------------------
    - lidar_model:
        library:
          vendor: velodyne
          model: ultra_puck
        name: LIDAR_POINT_CLOUD_VLP32_LF
        mount:
          px: 0.0
          py: 0.0
          pz: 2.4
          rpy:
            roll: 0.0
            pitch: 0.0
            yaw: 0.0
        standard_params:
          frame_rate: 100.0
          detector_params:
            range: {min: 0, max: 90}
        format:
          data: ROS_TOPIC
          semantic_segmentation: true
          intensity:
            quantization: 8.0
            units: REFLECTIVITY_SCALED
            log_scale: false
            range: {min: 0.01, max: 0.5}
            
            
    # lane_marker_sensors:
    # - name: Lane Sensor
    #   sensor_view:
    #     mount:
    #     sector_fov:
    #       distance_near: 1.0
    #       distance_far: 150.0
    #       yaw_start: !math "-pi"  # 180 degrees to the right
    #       yaw_length: !math "2*pi"  # 360 degrees counter-clockwise (top-down view)
    #   sensor_output:
    #     reporting_frame: MAP
    #   lane_stitching_distance: 0.2  # Merges lane segments within this tolerance
    # actor_sensors:
    # - name: Actor Sensor
    #   sensor_view:
    #     mount:
    #       rpy:
    #         yaw: 0
    #     sector_fov:
    #       distance_far: 200.0
    #       yaw_length: !math "2.0 * pi"
    #   sensor_output:
    #     reporting_frame: MAP
    #   sensor_filters:
    #   - actor_percent_occlusion: {} 
 

